"""TensorFlow Embedding Projector ì—°ë™ - ì¸ë„¤ì¼ ì„ë² ë”© ì‹œê°í™”"""
from typing import List, Dict
import numpy as np
from pathlib import Path
import json
import logfire


class EmbeddingVisualizer:
    """
import logging
    Pinecone ì„ë² ë”©ì„ TensorFlow Embedding Projectorë¡œ ì‹œê°í™”

    ì‚¬ìš© ëª©ì :
    - ê³ ì„±ê³¼ vs ì €ì„±ê³¼ ì¸ë„¤ì¼ íŒ¨í„´ ì‹œê°ì  ë¹„êµ
    - ìì‹ ì˜ ì»¨í…ì¸  vs íƒ€ì¸ì˜ ì»¨í…ì¸  í´ëŸ¬ìŠ¤í„°ë§
    - í”Œë«í¼ë³„ (YouTube, Facebook, Instagram) ì„ë² ë”© ë¶„í¬
    - t-SNE, PCA, UMAPìœ¼ë¡œ ì°¨ì› ì¶•ì†Œ ì‹œê°í™”
    """

    def __init__(self, output_dir: str = "./embeddings_viz"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.logger = logging.getLogger(__name__)

    def export_for_projector(
        self,
        pinecone_index,
        user_id: str,
        max_vectors: int = 1000
    ) -> str:
        """
        Pineconeì—ì„œ ì„ë² ë”© ì¶”ì¶œ í›„ TensorBoard Projector í˜•ì‹ìœ¼ë¡œ ì €ì¥

        ìƒì„± íŒŒì¼:
        - embeddings.tsv: ë²¡í„° ë°ì´í„° (N x D)
        - metadata.tsv: ë©”íƒ€ë°ì´í„° (ì œëª©, ì„±ê³¼, í”Œë«í¼ ë“±)

        Args:
            pinecone_index: Pinecone ì¸ë±ìŠ¤
            user_id: ì‚¬ìš©ì ID
            max_vectors: ìµœëŒ€ ë²¡í„° ìˆ˜

        Returns:
            ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        """
        with self.logger.span("embedding_viz.export"):
            # 1. Pineconeì—ì„œ ë²¡í„° ì¡°íšŒ
            # ëª¨ë“  ë²¡í„° ê°€ì ¸ì˜¤ê¸° (ì¿¼ë¦¬ ë²¡í„° ì—†ì´)
            # Pinecone v3ì—ì„œëŠ” list() ì‚¬ìš©
            try:
                # ë”ë¯¸ ì¿¼ë¦¬ë¡œ ìœ ì‚¬ ë²¡í„° ê°€ì ¸ì˜¤ê¸°
                dummy_vector = [0.0] * 512  # CLIP ë²¡í„° ì°¨ì›

                # ìì‹ ì˜ ì»¨í…ì¸ 
                own_results = pinecone_index.query(
                    vector=dummy_vector,
                    top_k=max_vectors // 2,
                    filter={"is_own_content": {"$eq": True}, "user_id": {"$eq": user_id}},
                    include_metadata=True,
                    include_values=True
                )

                # íƒ€ì¸ì˜ ì»¨í…ì¸ 
                others_results = pinecone_index.query(
                    vector=dummy_vector,
                    top_k=max_vectors // 2,
                    filter={"is_own_content": {"$ne": True}},
                    include_metadata=True,
                    include_values=True
                )

                all_vectors = own_results.get('matches', []) + others_results.get('matches', [])

            except Exception as e:
                self.logger.error(f"Pinecone query failed: {e}")
                # í´ë°±: ë”ë¯¸ ë°ì´í„°
                all_vectors = []

            if not all_vectors:
                self.logger.warning("No vectors found, using dummy data")
                return self._create_dummy_visualization()

            # 2. TSV íŒŒì¼ ìƒì„±
            embeddings_path = self.output_dir / "embeddings.tsv"
            metadata_path = self.output_dir / "metadata.tsv"

            with open(embeddings_path, 'w') as emb_file, \
                 open(metadata_path, 'w') as meta_file:

                # ë©”íƒ€ë°ì´í„° í—¤ë”
                meta_file.write("Title\tPlatform\tPerformance\tViews\tOwnership\n")

                for match in all_vectors:
                    vector = match.get('values', [])
                    metadata = match.get('metadata', {})

                    # ë²¡í„° ì €ì¥ (íƒ­ êµ¬ë¶„)
                    emb_file.write('\t'.join(map(str, vector)) + '\n')

                    # ë©”íƒ€ë°ì´í„° ì €ì¥
                    title = metadata.get('title', 'Unknown')[:50]  # ì œëª© ê¸¸ì´ ì œí•œ
                    platform = metadata.get('platform', 'youtube')
                    performance = metadata.get('performance_label', 'medium')
                    views = metadata.get('views', 0)
                    ownership = 'Own' if metadata.get('is_own_content', False) else 'Others'

                    meta_file.write(f"{title}\t{platform}\t{performance}\t{views}\t{ownership}\n")

            # 3. TensorBoard ì„¤ì • íŒŒì¼ ìƒì„±
            self._create_projector_config()

            self.logger.info(f"Exported {len(all_vectors)} embeddings to {self.output_dir}")

            return str(self.output_dir)

    def _create_projector_config(self):
        """
        TensorBoard Projector ì„¤ì • íŒŒì¼ (projector_config.pbtxt)

        TensorBoard ì‹¤í–‰:
        tensorboard --logdir=./embeddings_viz
        """
        config_path = self.output_dir / "projector_config.pbtxt"

        config_content = """
embeddings {
  tensor_name: "Thumbnail Embeddings"
  tensor_path: "embeddings.tsv"
  metadata_path: "metadata.tsv"
}
"""

        with open(config_path, 'w') as f:
            f.write(config_content.strip())

    def _create_dummy_visualization(self) -> str:
        """ë”ë¯¸ ë°ì´í„°ë¡œ ì‹œê°í™” ì˜ˆì œ ìƒì„±"""
        # 100ê°œ ë”ë¯¸ ë²¡í„° (512ì°¨ì›)
        np.random.seed(42)

        # í´ëŸ¬ìŠ¤í„° 3ê°œ
        cluster1 = np.random.randn(30, 512) + [1, 0] + [0]*510  # ê³ ì„±ê³¼
        cluster2 = np.random.randn(30, 512) + [0, 1] + [0]*510  # ì¤‘ì„±ê³¼
        cluster3 = np.random.randn(40, 512) + [-1, -1] + [0]*510  # ì €ì„±ê³¼

        all_embeddings = np.vstack([cluster1, cluster2, cluster3])

        # TSV ì €ì¥
        embeddings_path = self.output_dir / "embeddings.tsv"
        metadata_path = self.output_dir / "metadata.tsv"

        with open(embeddings_path, 'w') as emb_file, \
             open(metadata_path, 'w') as meta_file:

            meta_file.write("Title\tPlatform\tPerformance\tViews\tOwnership\n")

            for i, vec in enumerate(all_embeddings):
                emb_file.write('\t'.join(map(str, vec)) + '\n')

                if i < 30:
                    meta_file.write(f"High Perf Video {i}\tyoutube\thigh\t150000\tOwn\n")
                elif i < 60:
                    meta_file.write(f"Medium Perf Video {i}\tfacebook\tmedium\t50000\tOwn\n")
                else:
                    meta_file.write(f"Others Video {i}\tinstagram\thigh\t200000\tOthers\n")

        self._create_projector_config()

        return str(self.output_dir)

    def generate_visualization_html(self) -> str:
        """
        ì„ë² ë”© ì‹œê°í™” HTML í˜ì´ì§€ ìƒì„± (Plotly ì‚¬ìš©)

        TensorBoard ëŒ€ì‹  ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ë°”ë¡œ ë³¼ ìˆ˜ ìˆëŠ” ëŒ€ì•ˆ
        """
        html_path = self.output_dir / "visualization.html"

        html_content = """
<!DOCTYPE html>
<html>
<head>
    <title>OmniVibe Pro - Thumbnail Embeddings Visualization</title>
    <script src="https://cdn.plot.ly/plotly-2.27.0.min.js"></script>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        h1 { color: #333; }
        #plot { width: 100%; height: 800px; }
        .info { background: #f5f5f5; padding: 15px; border-radius: 5px; margin-bottom: 20px; }
    </style>
</head>
<body>
    <h1>ğŸ“Š Thumbnail Embeddings Visualization</h1>

    <div class="info">
        <h3>ì‹œê°í™” ê°€ì´ë“œ</h3>
        <ul>
            <li><strong>ê³ ì„±ê³¼ í´ëŸ¬ìŠ¤í„°</strong>: ë¹¨ê°„ìƒ‰ í¬ì¸íŠ¸ë“¤ì´ ëª¨ì—¬ìˆëŠ” ì˜ì—­</li>
            <li><strong>ìì‹ ì˜ ì»¨í…ì¸ </strong>: ì›(â—) ë§ˆì»¤</li>
            <li><strong>íƒ€ì¸ì˜ ì»¨í…ì¸ </strong>: ë³„(â˜…) ë§ˆì»¤</li>
            <li><strong>ì¸í„°ë™ì…˜</strong>: ë§ˆìš°ìŠ¤ë¡œ ë“œë˜ê·¸í•˜ì—¬ íšŒì „, ì¤Œ ê°€ëŠ¥</li>
        </ul>
    </div>

    <div id="plot"></div>

    <script>
        // TODO: embeddings.tsvì™€ metadata.tsv ë¡œë“œ í›„ Plotlyë¡œ ì‹œê°í™”
        // í˜„ì¬ëŠ” ë”ë¯¸ ë°ì´í„°

        const trace1 = {
            x: [1, 2, 3, 4, 5],
            y: [1, 3, 2, 4, 3],
            mode: 'markers',
            type: 'scatter',
            name: 'High Performance (Own)',
            marker: { size: 12, color: 'red', symbol: 'circle' }
        };

        const trace2 = {
            x: [2, 3, 4, 5, 6],
            y: [3, 4, 2, 5, 4],
            mode: 'markers',
            type: 'scatter',
            name: 'High Performance (Others)',
            marker: { size: 12, color: 'orange', symbol: 'star' }
        };

        const layout = {
            title: 'Thumbnail Embeddings (t-SNE 2D)',
            xaxis: { title: 'Dimension 1' },
            yaxis: { title: 'Dimension 2' },
            hovermode: 'closest'
        };

        Plotly.newPlot('plot', [trace1, trace2], layout);
    </script>

    <div class="info" style="margin-top: 20px;">
        <h3>ğŸ¯ ì¸ì‚¬ì´íŠ¸</h3>
        <p>TensorBoard ì‹¤í–‰ ë°©ë²•:</p>
        <pre>cd backend
tensorboard --logdir=./embeddings_viz</pre>
        <p>ê·¸ ë‹¤ìŒ ë¸Œë¼ìš°ì €ì—ì„œ <code>http://localhost:6006</code> ì ‘ì†</p>
    </div>
</body>
</html>
"""

        with open(html_path, 'w') as f:
            f.write(html_content)

        self.logger.info(f"Created visualization HTML at {html_path}")
        return str(html_path)

    def analyze_clusters(self, embeddings: np.ndarray, metadata: List[Dict]) -> Dict:
        """
        ì„ë² ë”© í´ëŸ¬ìŠ¤í„° ë¶„ì„ (K-means)

        Returns:
            í´ëŸ¬ìŠ¤í„°ë³„ ì„±ê³¼ í†µê³„
        """
        from sklearn.cluster import KMeans

        # 3ê°œ í´ëŸ¬ìŠ¤í„°ë¡œ ë¶„ë¥˜
        kmeans = KMeans(n_clusters=3, random_state=42)
        labels = kmeans.fit_predict(embeddings)

        cluster_stats = {}
        for cluster_id in range(3):
            cluster_indices = np.where(labels == cluster_id)[0]
            cluster_metadata = [metadata[i] for i in cluster_indices]

            avg_performance = np.mean([
                m.get('performance_score', 50) for m in cluster_metadata
            ])

            cluster_stats[f'Cluster {cluster_id}'] = {
                'size': len(cluster_indices),
                'avg_performance': avg_performance,
                'dominant_platform': self._most_common(
                    [m.get('platform', 'unknown') for m in cluster_metadata]
                )
            }

        return cluster_stats

    def _most_common(self, lst: List) -> str:
        """ë¦¬ìŠ¤íŠ¸ì—ì„œ ê°€ì¥ ë¹ˆë²ˆí•œ ê°’"""
        if not lst:
            return "unknown"
        return max(set(lst), key=lst.count)
