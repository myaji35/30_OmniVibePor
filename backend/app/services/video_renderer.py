"""SlideVideoRenderer - ì˜ìƒ í´ë¦½ + ì˜¤ë””ì˜¤ + ìë§‰ â†’ ìµœì¢… ë Œë”ë§

FFmpeg ê¸°ë°˜ ê³ í’ˆì§ˆ ì˜ìƒ ë Œë”ë§ ì‹œìŠ¤í…œ:
- ì—¬ëŸ¬ í´ë¦½ ë³‘í•© (ì „í™˜ íš¨ê³¼ ì§€ì›)
- ì˜¤ë””ì˜¤ ë¯¹ì‹± (ë‚˜ë ˆì´ì…˜ + BGM)
- ìë§‰ ì˜¤ë²„ë ˆì´
- í”Œë«í¼ë³„ ìµœì í™” (YouTube, Instagram, TikTok)
"""

from typing import List, Optional, Dict, Any, Literal
from pathlib import Path
import logging
import subprocess
import tempfile
import time
from contextlib import nullcontext
import ffmpeg
import os

from app.core.config import get_settings

settings = get_settings()

# Logfire availability check
try:
    import logfire
    LOGFIRE_AVAILABLE = settings.LOGFIRE_TOKEN and settings.LOGFIRE_TOKEN != "your_logfire_token_here"
except Exception:
    LOGFIRE_AVAILABLE = False


# í”Œë«í¼ë³„ ì‚¬ì–‘
PLATFORM_SPECS = {
    "youtube": {
        "resolution": "1920x1080",  # 16:9
        "width": 1920,
        "height": 1080,
        "bitrate": "8M",
        "fps": 30,
        "audio_bitrate": "192k",
        "description": "YouTube ìµœì í™” (Full HD, 16:9)"
    },
    "instagram": {
        "resolution": "1080x1350",  # 4:5 (í”¼ë“œ)
        "width": 1080,
        "height": 1350,
        "bitrate": "5M",
        "fps": 30,
        "audio_bitrate": "128k",
        "description": "Instagram í”¼ë“œ ìµœì í™” (4:5)"
    },
    "instagram_story": {
        "resolution": "1080x1920",  # 9:16 (ìŠ¤í† ë¦¬/ë¦´ìŠ¤)
        "width": 1080,
        "height": 1920,
        "bitrate": "4M",
        "fps": 30,
        "audio_bitrate": "128k",
        "description": "Instagram ìŠ¤í† ë¦¬/ë¦´ìŠ¤ ìµœì í™” (9:16)"
    },
    "tiktok": {
        "resolution": "1080x1920",  # 9:16
        "width": 1080,
        "height": 1920,
        "bitrate": "4M",
        "fps": 30,
        "audio_bitrate": "128k",
        "description": "TikTok ìµœì í™” (9:16)"
    },
    "facebook": {
        "resolution": "1280x720",  # 16:9 (HD)
        "width": 1280,
        "height": 720,
        "bitrate": "6M",
        "fps": 30,
        "audio_bitrate": "128k",
        "description": "Facebook ìµœì í™” (720p)"
    },
}


# FFmpeg xfade ì „í™˜ íš¨ê³¼ (30ê°€ì§€ ì¤‘ ì—„ì„ )
TRANSITION_EFFECTS = {
    "fade": {
        "name": "fade",
        "description": "í˜ì´ë“œ ì „í™˜ (ê¸°ë³¸)"
    },
    "wipeleft": {
        "name": "wipeleft",
        "description": "ì™¼ìª½ì—ì„œ ì™€ì´í”„"
    },
    "wiperight": {
        "name": "wiperight",
        "description": "ì˜¤ë¥¸ìª½ì—ì„œ ì™€ì´í”„"
    },
    "wipeup": {
        "name": "wipeup",
        "description": "ìœ„ì—ì„œ ì™€ì´í”„"
    },
    "wipedown": {
        "name": "wipedown",
        "description": "ì•„ë˜ì—ì„œ ì™€ì´í”„"
    },
    "slideleft": {
        "name": "slideleft",
        "description": "ì™¼ìª½ìœ¼ë¡œ ìŠ¬ë¼ì´ë“œ"
    },
    "slideright": {
        "name": "slideright",
        "description": "ì˜¤ë¥¸ìª½ìœ¼ë¡œ ìŠ¬ë¼ì´ë“œ"
    },
    "slideup": {
        "name": "slideup",
        "description": "ìœ„ë¡œ ìŠ¬ë¼ì´ë“œ"
    },
    "slidedown": {
        "name": "slidedown",
        "description": "ì•„ë˜ë¡œ ìŠ¬ë¼ì´ë“œ"
    },
    "circlecrop": {
        "name": "circlecrop",
        "description": "ì›í˜• í¬ë¡­ ì „í™˜"
    },
    "rectcrop": {
        "name": "rectcrop",
        "description": "ì‚¬ê°í˜• í¬ë¡­ ì „í™˜"
    },
    "distance": {
        "name": "distance",
        "description": "ê±°ë¦¬ ì™œê³¡ ì „í™˜"
    },
    "fadeblack": {
        "name": "fadeblack",
        "description": "ê²€ì€ìƒ‰ìœ¼ë¡œ í˜ì´ë“œ"
    },
    "fadewhite": {
        "name": "fadewhite",
        "description": "í°ìƒ‰ìœ¼ë¡œ í˜ì´ë“œ"
    },
    "radial": {
        "name": "radial",
        "description": "ë°©ì‚¬í˜• ì „í™˜"
    },
    "smoothleft": {
        "name": "smoothleft",
        "description": "ë¶€ë“œëŸ¬ìš´ ì™¼ìª½ ì „í™˜"
    },
    "smoothright": {
        "name": "smoothright",
        "description": "ë¶€ë“œëŸ¬ìš´ ì˜¤ë¥¸ìª½ ì „í™˜"
    },
    "smoothup": {
        "name": "smoothup",
        "description": "ë¶€ë“œëŸ¬ìš´ ìœ„ìª½ ì „í™˜"
    },
    "smoothdown": {
        "name": "smoothdown",
        "description": "ë¶€ë“œëŸ¬ìš´ ì•„ë˜ìª½ ì „í™˜"
    },
    "circleopen": {
        "name": "circleopen",
        "description": "ì›í˜• ì—´ê¸°"
    },
    "circleclose": {
        "name": "circleclose",
        "description": "ì›í˜• ë‹«ê¸°"
    },
    "vertopen": {
        "name": "vertopen",
        "description": "ìˆ˜ì§ ì—´ê¸°"
    },
    "vertclose": {
        "name": "vertclose",
        "description": "ìˆ˜ì§ ë‹«ê¸°"
    },
    "horzopen": {
        "name": "horzopen",
        "description": "ìˆ˜í‰ ì—´ê¸°"
    },
    "horzclose": {
        "name": "horzclose",
        "description": "ìˆ˜í‰ ë‹«ê¸°"
    },
    "dissolve": {
        "name": "dissolve",
        "description": "ë””ì¡¸ë¸Œ ì „í™˜"
    },
    "pixelize": {
        "name": "pixelize",
        "description": "í”½ì…€í™” ì „í™˜"
    },
    "diagtl": {
        "name": "diagtl",
        "description": "ëŒ€ê°ì„  (ì™¼ìª½ ìœ„)"
    },
    "diagtr": {
        "name": "diagtr",
        "description": "ëŒ€ê°ì„  (ì˜¤ë¥¸ìª½ ìœ„)"
    },
    "diagbl": {
        "name": "diagbl",
        "description": "ëŒ€ê°ì„  (ì™¼ìª½ ì•„ë˜)"
    },
    "diagbr": {
        "name": "diagbr",
        "description": "ëŒ€ê°ì„  (ì˜¤ë¥¸ìª½ ì•„ë˜)"
    },
}


# ìë§‰ ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹
SUBTITLE_STYLES = {
    "default": {
        "fontsize": 24,
        "fontcolor": "white",
        "borderw": 2,
        "bordercolor": "black",
        "alignment": 2,  # í•˜ë‹¨ ì¤‘ì•™
        "margin_v": 50,
        "description": "ê¸°ë³¸ ìŠ¤íƒ€ì¼ (í•˜ë‹¨ ì¤‘ì•™, í°ìƒ‰ ê¸€ì, ê²€ì€ìƒ‰ í…Œë‘ë¦¬)"
    },
    "youtube": {
        "fontsize": 28,
        "fontcolor": "white",
        "borderw": 3,
        "bordercolor": "black",
        "alignment": 2,
        "margin_v": 80,
        "description": "YouTube ìŠ¤íƒ€ì¼ (í° í°íŠ¸, í•˜ë‹¨ ì¤‘ì•™)"
    },
    "tiktok": {
        "fontsize": 32,
        "fontcolor": "yellow",
        "borderw": 4,
        "bordercolor": "black",
        "alignment": 5,  # ì¤‘ì•™
        "margin_v": 0,
        "description": "TikTok ìŠ¤íƒ€ì¼ (ë…¸ë€ìƒ‰, ì¤‘ì•™, í° í°íŠ¸)"
    },
    "instagram": {
        "fontsize": 26,
        "fontcolor": "white",
        "borderw": 2,
        "bordercolor": "black",
        "alignment": 2,
        "margin_v": 60,
        "description": "Instagram ìŠ¤íƒ€ì¼ (í•˜ë‹¨ ì¤‘ì•™)"
    },
    "minimal": {
        "fontsize": 22,
        "fontcolor": "white",
        "borderw": 1,
        "bordercolor": "black",
        "alignment": 2,
        "margin_v": 40,
        "description": "ë¯¸ë‹ˆë©€ ìŠ¤íƒ€ì¼ (ì‘ì€ í°íŠ¸, ì–‡ì€ í…Œë‘ë¦¬)"
    },
}


class VideoRenderer:
    """
    SlideVideoRenderer - FFmpeg ê¸°ë°˜ ì˜ìƒ ë Œë”ë§ ì‹œìŠ¤í…œ

    ì£¼ìš” ê¸°ëŠ¥:
    1. ì—¬ëŸ¬ ì˜ìƒ í´ë¦½ ë³‘í•© (ì „í™˜ íš¨ê³¼ ì§€ì›)
    2. ì˜¤ë””ì˜¤ ë¯¹ì‹± (ë‚˜ë ˆì´ì…˜ + BGM)
    3. ìë§‰ ì˜¤ë²„ë ˆì´
    4. í”Œë«í¼ë³„ ìµœì í™”

    ì‚¬ìš© ì˜ˆ:
        renderer = VideoRenderer()
        result = await renderer.render_video(
            video_clips=["clip1.mp4", "clip2.mp4", "clip3.mp4"],
            audio_path="narration.mp3",
            output_path="final.mp4",
            subtitle_path="subtitles.srt",
            transitions=["fade", "wipeleft", "slideup"],
            bgm_path="background.mp3",
            bgm_volume=0.2
        )
    """

    def __init__(self, output_dir: str = "./outputs/videos"):
        """
        Args:
            output_dir: ë Œë”ë§ëœ ì˜ìƒ ì €ì¥ ê²½ë¡œ
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.logger = logging.getLogger(__name__)

        # FFmpeg ì„¤ì¹˜ í™•ì¸
        self._check_ffmpeg()

    def _check_ffmpeg(self):
        """FFmpeg ì„¤ì¹˜ í™•ì¸"""
        try:
            result = subprocess.run(
                ["ffmpeg", "-version"],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                check=True
            )
            self.logger.info("âœ… FFmpeg is available")
        except (subprocess.CalledProcessError, FileNotFoundError) as e:
            self.logger.error(
                "âŒ FFmpeg not found. Please install FFmpeg:\n"
                "  macOS: brew install ffmpeg\n"
                "  Ubuntu: apt-get install ffmpeg\n"
                "  Windows: Download from https://ffmpeg.org/"
            )
            raise RuntimeError("FFmpeg is required but not installed") from e

    async def render_video(
        self,
        video_clips: List[str],
        audio_path: str,
        output_path: str,
        subtitle_path: Optional[str] = None,
        transitions: Optional[List[str]] = None,
        bgm_path: Optional[str] = None,
        bgm_volume: float = 0.2,
        transition_duration: float = 0.5,
        platform: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ìµœì¢… ì˜ìƒ ë Œë”ë§ (ì „ì²´ íŒŒì´í”„ë¼ì¸)

        ì›Œí¬í”Œë¡œìš°:
        1. í´ë¦½ ë³‘í•© (ì „í™˜ íš¨ê³¼ ì ìš©)
        2. ì˜¤ë””ì˜¤ ë¯¹ì‹± (ë‚˜ë ˆì´ì…˜ + BGM)
        3. ìë§‰ ì˜¤ë²„ë ˆì´
        4. í”Œë«í¼ë³„ ìµœì í™”

        Args:
            video_clips: ì˜ìƒ í´ë¦½ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            audio_path: ë‚˜ë ˆì´ì…˜ ì˜¤ë””ì˜¤ ê²½ë¡œ
            output_path: ìµœì¢… ì˜ìƒ ì €ì¥ ê²½ë¡œ
            subtitle_path: ìë§‰ íŒŒì¼ ê²½ë¡œ (.srt)
            transitions: ì „í™˜ íš¨ê³¼ ë¦¬ìŠ¤íŠ¸ (í´ë¦½ ê°œìˆ˜ - 1)
            bgm_path: ë°°ê²½ìŒì•… ê²½ë¡œ
            bgm_volume: BGM ë³¼ë¥¨ (0.0-1.0)
            transition_duration: ì „í™˜ íš¨ê³¼ ì§€ì† ì‹œê°„ (ì´ˆ)
            platform: í”Œë«í¼ë³„ ìµœì í™” ("youtube", "instagram", "tiktok" ë“±)

        Returns:
            {
                "status": "success",
                "output_path": "ìµœì¢… ì˜ìƒ ê²½ë¡œ",
                "file_size_mb": íŒŒì¼ í¬ê¸° (MB),
                "render_time": ë Œë”ë§ ì‹œê°„ (ì´ˆ),
                "steps": {
                    "merge_clips": {...},
                    "audio_mix": {...},
                    "subtitles": {...},
                    "platform_optimize": {...}
                }
            }
        """
        span_context = logfire.span("video_renderer.render") if LOGFIRE_AVAILABLE else nullcontext()

        async with span_context as main_span:
            start_time = time.time()

            self.logger.info(
                f"ğŸ¬ Starting video rendering pipeline:\n"
                f"  Clips: {len(video_clips)}\n"
                f"  Audio: {audio_path}\n"
                f"  Output: {output_path}\n"
                f"  Subtitles: {subtitle_path or 'None'}\n"
                f"  BGM: {bgm_path or 'None'}\n"
                f"  Platform: {platform or 'Generic'}"
            )

            # Logfire ì†ì„±
            if LOGFIRE_AVAILABLE:
                main_span.set_attribute("clip_count", len(video_clips))
                main_span.set_attribute("has_subtitles", subtitle_path is not None)
                main_span.set_attribute("has_bgm", bgm_path is not None)
                main_span.set_attribute("platform", platform or "generic")

            steps_info = {}
            current_video = None

            try:
                # 1ï¸âƒ£ í´ë¦½ ë³‘í•©
                if len(video_clips) == 1:
                    self.logger.info("ğŸ“¹ Single clip, skipping merge step")
                    current_video = video_clips[0]
                    steps_info["merge_clips"] = {
                        "skipped": True,
                        "reason": "single_clip"
                    }
                else:
                    merged_path = str(self.output_dir / f"merged_{int(time.time())}.mp4")
                    merge_result = self.merge_clips(
                        clips=video_clips,
                        output_path=merged_path,
                        transitions=transitions,
                        transition_duration=transition_duration
                    )
                    current_video = merged_path
                    steps_info["merge_clips"] = merge_result

                # 2ï¸âƒ£ ì˜¤ë””ì˜¤ ë¯¹ì‹±
                with_audio_path = str(self.output_dir / f"with_audio_{int(time.time())}.mp4")
                audio_result = self.add_audio_mix(
                    video_path=current_video,
                    audio_path=audio_path,
                    bgm_path=bgm_path,
                    output_path=with_audio_path,
                    bgm_volume=bgm_volume
                )
                current_video = with_audio_path
                steps_info["audio_mix"] = audio_result

                # 3ï¸âƒ£ ìë§‰ ì˜¤ë²„ë ˆì´ (ì„ íƒì )
                if subtitle_path:
                    with_subtitle_path = str(self.output_dir / f"with_subtitle_{int(time.time())}.mp4")
                    subtitle_result = self.add_subtitles_overlay(
                        video_path=current_video,
                        subtitle_path=subtitle_path,
                        output_path=with_subtitle_path,
                        style=platform or "default"
                    )
                    current_video = with_subtitle_path
                    steps_info["subtitles"] = subtitle_result
                else:
                    self.logger.info("ğŸ“ No subtitles, skipping overlay step")
                    steps_info["subtitles"] = {
                        "skipped": True,
                        "reason": "no_subtitle_file"
                    }

                # 4ï¸âƒ£ í”Œë«í¼ë³„ ìµœì í™” (ì„ íƒì )
                if platform and platform in PLATFORM_SPECS:
                    optimize_result = self.optimize_for_platform(
                        video_path=current_video,
                        platform=platform,
                        output_path=output_path
                    )
                    steps_info["platform_optimize"] = optimize_result
                else:
                    # ìµœì í™” ì—†ì´ ìµœì¢… ê²½ë¡œë¡œ ë³µì‚¬
                    import shutil
                    shutil.copy(current_video, output_path)
                    self.logger.info(f"ğŸ“¦ No platform optimization, copied to {output_path}")
                    steps_info["platform_optimize"] = {
                        "skipped": True,
                        "reason": "no_platform_specified"
                    }

                # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                self._cleanup_temp_files([
                    steps_info.get("merge_clips", {}).get("output_path"),
                    steps_info.get("audio_mix", {}).get("output_path"),
                    steps_info.get("subtitles", {}).get("output_path"),
                ])

                # ìµœì¢… í†µê³„
                render_time = time.time() - start_time
                file_size = Path(output_path).stat().st_size / (1024 * 1024)  # MB

                self.logger.info(
                    f"âœ… Rendering completed in {render_time:.1f}s\n"
                    f"  Output: {output_path}\n"
                    f"  Size: {file_size:.2f} MB"
                )

                return {
                    "status": "success",
                    "output_path": output_path,
                    "file_size_mb": round(file_size, 2),
                    "render_time": round(render_time, 2),
                    "steps": steps_info
                }

            except Exception as e:
                self.logger.error(f"âŒ Rendering failed: {e}", exc_info=True)
                raise

    def merge_clips(
        self,
        clips: List[str],
        output_path: str,
        transitions: Optional[List[str]] = None,
        transition_duration: float = 0.5
    ) -> Dict[str, Any]:
        """
        ì—¬ëŸ¬ í´ë¦½ ë³‘í•© (ì „í™˜ íš¨ê³¼ ì§€ì›)

        Args:
            clips: ì˜ìƒ í´ë¦½ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            output_path: ë³‘í•©ëœ ì˜ìƒ ì €ì¥ ê²½ë¡œ
            transitions: ì „í™˜ íš¨ê³¼ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ë‹¨ìˆœ concat)
            transition_duration: ì „í™˜ íš¨ê³¼ ì§€ì† ì‹œê°„ (ì´ˆ)

        Returns:
            {
                "output_path": "ë³‘í•©ëœ ì˜ìƒ ê²½ë¡œ",
                "method": "concat" | "xfade",
                "clip_count": í´ë¦½ ê°œìˆ˜,
                "transitions_used": ì‚¬ìš©ëœ ì „í™˜ íš¨ê³¼
            }
        """
        span_context = logfire.span("video_renderer.merge_clips") if LOGFIRE_AVAILABLE else nullcontext()

        with span_context:
            self.logger.info(f"ğŸ”— Merging {len(clips)} clips...")

            # ì „í™˜ íš¨ê³¼ ì—†ìœ¼ë©´ ë‹¨ìˆœ concat
            if not transitions:
                return self._simple_concat(clips, output_path)

            # ì „í™˜ íš¨ê³¼ ê°œìˆ˜ ê²€ì¦
            expected_transitions = len(clips) - 1
            if len(transitions) != expected_transitions:
                self.logger.warning(
                    f"âš ï¸ Transition count mismatch: expected {expected_transitions}, "
                    f"got {len(transitions)}. Using simple concat instead."
                )
                return self._simple_concat(clips, output_path)

            # xfade í•„í„°ë¡œ ì „í™˜ íš¨ê³¼ ì ìš©
            return self._merge_with_transitions(
                clips, output_path, transitions, transition_duration
            )

    def _simple_concat(self, clips: List[str], output_path: str) -> Dict[str, Any]:
        """
        ë‹¨ìˆœ í´ë¦½ ë³‘í•© (ì „í™˜ íš¨ê³¼ ì—†ìŒ)

        FFmpeg concat demuxer ì‚¬ìš©
        """
        start_time = time.time()

        # concat.txt íŒŒì¼ ìƒì„±
        concat_file = tempfile.NamedTemporaryFile(
            mode='w', suffix='.txt', delete=False
        )

        try:
            for clip in clips:
                # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                abs_clip = str(Path(clip).resolve())
                concat_file.write(f"file '{abs_clip}'\n")

            concat_file.close()

            # FFmpeg concat ì‹¤í–‰
            cmd = [
                "ffmpeg",
                "-f", "concat",
                "-safe", "0",
                "-i", concat_file.name,
                "-c", "copy",  # ì¬ì¸ì½”ë”© ì—†ì´ ë³µì‚¬ (ë¹ ë¦„)
                "-y",  # ë®ì–´ì“°ê¸°
                output_path
            ]

            self.logger.debug(f"Running: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                check=True
            )

            elapsed = time.time() - start_time

            self.logger.info(
                f"âœ… Clips concatenated in {elapsed:.1f}s (method: concat)"
            )

            return {
                "output_path": output_path,
                "method": "concat",
                "clip_count": len(clips),
                "transitions_used": None,
                "elapsed_time": round(elapsed, 2)
            }

        finally:
            # concat íŒŒì¼ ì‚­ì œ
            Path(concat_file.name).unlink(missing_ok=True)

    def _merge_with_transitions(
        self,
        clips: List[str],
        output_path: str,
        transitions: List[str],
        transition_duration: float
    ) -> Dict[str, Any]:
        """
        ì „í™˜ íš¨ê³¼ë¥¼ ì ìš©í•œ í´ë¦½ ë³‘í•©

        FFmpeg xfade í•„í„° ì‚¬ìš©
        """
        start_time = time.time()

        # ì „í™˜ íš¨ê³¼ ê²€ì¦ ë° ë§¤í•‘
        validated_transitions = []
        for t in transitions:
            if t in TRANSITION_EFFECTS:
                validated_transitions.append(TRANSITION_EFFECTS[t]["name"])
            else:
                self.logger.warning(
                    f"âš ï¸ Unknown transition '{t}', using 'fade' instead"
                )
                validated_transitions.append("fade")

        # ê° í´ë¦½ì˜ ê¸¸ì´ ì¶”ì¶œ (xfade offset ê³„ì‚°ìš©)
        clip_durations = []
        for clip in clips:
            probe = ffmpeg.probe(clip)
            duration = float(probe['format']['duration'])
            clip_durations.append(duration)

        self.logger.debug(f"Clip durations: {clip_durations}")

        # xfade í•„í„° ì²´ì¸ ìƒì„±
        # [0:v][1:v]xfade=transition=fade:duration=0.5:offset=2.5[v01];
        # [v01][2:v]xfade=transition=wipeleft:duration=0.5:offset=5.0[v02];

        filter_parts = []
        offset = 0.0

        for i, transition in enumerate(validated_transitions):
            if i == 0:
                # ì²« ë²ˆì§¸ ì „í™˜: [0:v][1:v]
                offset = clip_durations[0] - transition_duration
                filter_parts.append(
                    f"[0:v][1:v]xfade=transition={transition}:"
                    f"duration={transition_duration}:offset={offset}[v{i+1}]"
                )
            else:
                # ì´í›„ ì „í™˜: [vN][N+1:v]
                offset += clip_durations[i] - transition_duration
                filter_parts.append(
                    f"[v{i}][{i+1}:v]xfade=transition={transition}:"
                    f"duration={transition_duration}:offset={offset}[v{i+1}]"
                )

        filter_complex = ";".join(filter_parts)
        final_output = f"[v{len(clips)-1}]"

        self.logger.debug(f"Filter complex: {filter_complex}")

        # FFmpeg ëª…ë ¹ êµ¬ì„±
        cmd = ["ffmpeg"]

        # ì…ë ¥ íŒŒì¼ë“¤
        for clip in clips:
            cmd.extend(["-i", clip])

        # í•„í„° ë° ì¶œë ¥
        cmd.extend([
            "-filter_complex", filter_complex,
            "-map", final_output,
            "-c:v", "libx264",
            "-preset", "medium",
            "-crf", "23",
            "-y",
            output_path
        ])

        self.logger.debug(f"Running: {' '.join(cmd)}")

        result = subprocess.run(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            check=True
        )

        elapsed = time.time() - start_time

        self.logger.info(
            f"âœ… Clips merged with transitions in {elapsed:.1f}s\n"
            f"  Transitions: {', '.join(validated_transitions)}"
        )

        return {
            "output_path": output_path,
            "method": "xfade",
            "clip_count": len(clips),
            "transitions_used": validated_transitions,
            "transition_duration": transition_duration,
            "elapsed_time": round(elapsed, 2)
        }

    def add_audio_mix(
        self,
        video_path: str,
        audio_path: str,
        output_path: str,
        bgm_path: Optional[str] = None,
        bgm_volume: float = 0.2
    ) -> Dict[str, Any]:
        """
        ì˜¤ë””ì˜¤ ë¯¹ì‹± (ë‚˜ë ˆì´ì…˜ + BGM)

        Args:
            video_path: ì…ë ¥ ì˜ìƒ ê²½ë¡œ
            audio_path: ë‚˜ë ˆì´ì…˜ ì˜¤ë””ì˜¤ ê²½ë¡œ
            output_path: ì¶œë ¥ ì˜ìƒ ê²½ë¡œ
            bgm_path: ë°°ê²½ìŒì•… ê²½ë¡œ (ì„ íƒì )
            bgm_volume: BGM ë³¼ë¥¨ (0.0-1.0)

        Returns:
            {
                "output_path": "ì˜¤ë””ì˜¤ ë¯¹ì‹±ëœ ì˜ìƒ ê²½ë¡œ",
                "has_bgm": True/False,
                "bgm_volume": ë³¼ë¥¨ ê°’
            }
        """
        span_context = logfire.span("video_renderer.audio_mix") if LOGFIRE_AVAILABLE else nullcontext()

        with span_context:
            start_time = time.time()

            if not bgm_path:
                # BGM ì—†ìœ¼ë©´ ë‹¨ìˆœ ì˜¤ë””ì˜¤ ë³‘í•©
                self.logger.info("ğŸµ Adding narration audio (no BGM)...")

                cmd = [
                    "ffmpeg",
                    "-i", video_path,
                    "-i", audio_path,
                    "-c:v", "copy",  # ì˜ìƒ ì¬ì¸ì½”ë”© ì•ˆ í•¨
                    "-c:a", "aac",
                    "-b:a", "192k",
                    "-map", "0:v:0",  # ì˜ìƒì€ ì²« ë²ˆì§¸ ì…ë ¥
                    "-map", "1:a:0",  # ì˜¤ë””ì˜¤ëŠ” ë‘ ë²ˆì§¸ ì…ë ¥
                    "-shortest",  # ì§§ì€ ìª½ì— ë§ì¶¤
                    "-y",
                    output_path
                ]

                self.logger.debug(f"Running: {' '.join(cmd)}")

                subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

                elapsed = time.time() - start_time

                self.logger.info(f"âœ… Audio added in {elapsed:.1f}s")

                return {
                    "output_path": output_path,
                    "has_bgm": False,
                    "bgm_volume": 0.0,
                    "elapsed_time": round(elapsed, 2)
                }

            else:
                # BGM ìˆìœ¼ë©´ amix í•„í„°ë¡œ ë¯¹ì‹±
                self.logger.info(
                    f"ğŸµ Mixing narration + BGM (volume: {bgm_volume})..."
                )

                # amix í•„í„°: ë‚˜ë ˆì´ì…˜ 100% + BGM 20%
                filter_complex = (
                    f"[1:a]volume=1.0[a1];"
                    f"[2:a]volume={bgm_volume}[a2];"
                    f"[a1][a2]amix=inputs=2:duration=first[aout]"
                )

                cmd = [
                    "ffmpeg",
                    "-i", video_path,
                    "-i", audio_path,
                    "-i", bgm_path,
                    "-filter_complex", filter_complex,
                    "-map", "0:v:0",
                    "-map", "[aout]",
                    "-c:v", "copy",
                    "-c:a", "aac",
                    "-b:a", "192k",
                    "-shortest",
                    "-y",
                    output_path
                ]

                self.logger.debug(f"Running: {' '.join(cmd)}")

                subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

                elapsed = time.time() - start_time

                self.logger.info(
                    f"âœ… Audio mixed in {elapsed:.1f}s "
                    f"(narration + BGM at {bgm_volume*100:.0f}%)"
                )

                return {
                    "output_path": output_path,
                    "has_bgm": True,
                    "bgm_volume": bgm_volume,
                    "elapsed_time": round(elapsed, 2)
                }

    def add_subtitles_overlay(
        self,
        video_path: str,
        subtitle_path: str,
        output_path: str,
        style: str = "default"
    ) -> Dict[str, Any]:
        """
        ìë§‰ ì˜¤ë²„ë ˆì´

        Args:
            video_path: ì…ë ¥ ì˜ìƒ ê²½ë¡œ
            subtitle_path: ìë§‰ íŒŒì¼ ê²½ë¡œ (.srt)
            output_path: ì¶œë ¥ ì˜ìƒ ê²½ë¡œ
            style: ìë§‰ ìŠ¤íƒ€ì¼ ("default", "youtube", "tiktok", "instagram", "minimal")

        Returns:
            {
                "output_path": "ìë§‰ì´ ì¶”ê°€ëœ ì˜ìƒ ê²½ë¡œ",
                "style": ì‚¬ìš©ëœ ìŠ¤íƒ€ì¼,
                "subtitle_file": ìë§‰ íŒŒì¼ ê²½ë¡œ
            }
        """
        span_context = logfire.span("video_renderer.add_subtitles") if LOGFIRE_AVAILABLE else nullcontext()

        with span_context:
            start_time = time.time()

            # ìŠ¤íƒ€ì¼ ì„ íƒ
            if style not in SUBTITLE_STYLES:
                self.logger.warning(
                    f"âš ï¸ Unknown subtitle style '{style}', using 'default'"
                )
                style = "default"

            style_config = SUBTITLE_STYLES[style]

            self.logger.info(
                f"ğŸ“ Adding subtitles (style: {style})..."
            )

            # ìë§‰ íŒŒì¼ ê²½ë¡œ ì´ìŠ¤ì¼€ì´í”„ (Windows í˜¸í™˜)
            subtitle_path_escaped = subtitle_path.replace("\\", "/").replace(":", "\\:")

            # subtitles í•„í„°
            # force_style: ìŠ¤íƒ€ì¼ ê°•ì œ ì ìš©
            force_style = (
                f"FontSize={style_config['fontsize']},"
                f"PrimaryColour=&H{self._color_to_ass(style_config['fontcolor'])},"
                f"OutlineColour=&H{self._color_to_ass(style_config['bordercolor'])},"
                f"BorderStyle=1,"
                f"Outline={style_config['borderw']},"
                f"Alignment={style_config['alignment']},"
                f"MarginV={style_config['margin_v']}"
            )

            cmd = [
                "ffmpeg",
                "-i", video_path,
                "-vf", f"subtitles={subtitle_path_escaped}:force_style='{force_style}'",
                "-c:a", "copy",  # ì˜¤ë””ì˜¤ ì¬ì¸ì½”ë”© ì•ˆ í•¨
                "-c:v", "libx264",
                "-preset", "medium",
                "-crf", "23",
                "-y",
                output_path
            ]

            self.logger.debug(f"Running: {' '.join(cmd)}")

            subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

            elapsed = time.time() - start_time

            self.logger.info(
                f"âœ… Subtitles added in {elapsed:.1f}s (style: {style})"
            )

            return {
                "output_path": output_path,
                "style": style,
                "subtitle_file": subtitle_path,
                "elapsed_time": round(elapsed, 2)
            }

    def optimize_for_platform(
        self,
        video_path: str,
        platform: str,
        output_path: str
    ) -> Dict[str, Any]:
        """
        í”Œë«í¼ë³„ ìµœì í™” (í•´ìƒë„, ë¹„íŠ¸ë ˆì´íŠ¸, FPS)

        Args:
            video_path: ì…ë ¥ ì˜ìƒ ê²½ë¡œ
            platform: í”Œë«í¼ ("youtube", "instagram", "tiktok", "facebook")
            output_path: ì¶œë ¥ ì˜ìƒ ê²½ë¡œ

        Returns:
            {
                "output_path": "ìµœì í™”ëœ ì˜ìƒ ê²½ë¡œ",
                "platform": í”Œë«í¼ ì´ë¦„,
                "resolution": í•´ìƒë„,
                "bitrate": ë¹„íŠ¸ë ˆì´íŠ¸
            }
        """
        span_context = logfire.span("video_renderer.platform_optimize") if LOGFIRE_AVAILABLE else nullcontext()

        with span_context:
            start_time = time.time()

            if platform not in PLATFORM_SPECS:
                raise ValueError(
                    f"Unknown platform '{platform}'. "
                    f"Available: {', '.join(PLATFORM_SPECS.keys())}"
                )

            spec = PLATFORM_SPECS[platform]

            self.logger.info(
                f"ğŸ“± Optimizing for {platform}:\n"
                f"  Resolution: {spec['resolution']}\n"
                f"  Bitrate: {spec['bitrate']}\n"
                f"  FPS: {spec['fps']}"
            )

            # scale í•„í„°: ì¢…íš¡ë¹„ ìœ ì§€í•˜ë©° ë¦¬ì‚¬ì´ì§• + íŒ¨ë”©
            scale_filter = (
                f"scale={spec['width']}:{spec['height']}:"
                f"force_original_aspect_ratio=decrease,"
                f"pad={spec['width']}:{spec['height']}:(ow-iw)/2:(oh-ih)/2"
            )

            cmd = [
                "ffmpeg",
                "-i", video_path,
                "-vf", scale_filter,
                "-r", str(spec["fps"]),
                "-b:v", spec["bitrate"],
                "-c:v", "libx264",
                "-preset", "medium",
                "-crf", "23",
                "-c:a", "aac",
                "-b:a", spec["audio_bitrate"],
                "-ar", "48000",  # ìƒ˜í”Œë ˆì´íŠ¸ 48kHz
                "-y",
                output_path
            ]

            self.logger.debug(f"Running: {' '.join(cmd)}")

            subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

            elapsed = time.time() - start_time

            self.logger.info(
                f"âœ… Platform optimization completed in {elapsed:.1f}s"
            )

            return {
                "output_path": output_path,
                "platform": platform,
                "resolution": spec["resolution"],
                "bitrate": spec["bitrate"],
                "fps": spec["fps"],
                "elapsed_time": round(elapsed, 2)
            }

    def _color_to_ass(self, color: str) -> str:
        """
        CSS ìƒ‰ìƒì„ ASS ìë§‰ í˜•ì‹ìœ¼ë¡œ ë³€í™˜

        Args:
            color: CSS ìƒ‰ìƒ ("white", "black", "yellow" ë“±)

        Returns:
            ASS ìƒ‰ìƒ ì½”ë“œ (BGR í˜•ì‹)
        """
        color_map = {
            "white": "FFFFFF",
            "black": "000000",
            "yellow": "00FFFF",
            "red": "0000FF",
            "green": "00FF00",
            "blue": "FF0000",
            "cyan": "FFFF00",
            "magenta": "FF00FF",
        }

        return color_map.get(color.lower(), "FFFFFF")

    def _cleanup_temp_files(self, file_paths: List[Optional[str]]):
        """ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
        for path in file_paths:
            if path and Path(path).exists():
                try:
                    Path(path).unlink()
                    self.logger.debug(f"ğŸ—‘ï¸  Deleted temp file: {path}")
                except Exception as e:
                    self.logger.warning(f"Failed to delete temp file {path}: {e}")

    def get_available_transitions(self) -> Dict[str, str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì „í™˜ íš¨ê³¼ ëª©ë¡"""
        return {
            name: info["description"]
            for name, info in TRANSITION_EFFECTS.items()
        }

    def get_available_platforms(self) -> Dict[str, str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ í”Œë«í¼ ëª©ë¡"""
        return {
            name: spec["description"]
            for name, spec in PLATFORM_SPECS.items()
        }

    def get_available_subtitle_styles(self) -> Dict[str, str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ìë§‰ ìŠ¤íƒ€ì¼ ëª©ë¡"""
        return {
            name: style["description"]
            for name, style in SUBTITLE_STYLES.items()
        }


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_renderer_instance = None


def get_video_renderer() -> VideoRenderer:
    """VideoRenderer ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤"""
    global _renderer_instance
    if _renderer_instance is None:
        _renderer_instance = VideoRenderer()
    return _renderer_instance
