"""Celery ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì • - ì„±ëŠ¥ ìµœì í™”"""
import logging
import time
from celery import Celery
from celery.signals import task_prerun, task_postrun, task_failure, task_retry
from kombu import Queue, Exchange

from app.core.config import get_settings

settings = get_settings()

# Celery ì•± ì´ˆê¸°í™”
celery_app = Celery(
    "omnivibe",
    broker=settings.CELERY_BROKER_URL,
    backend=settings.CELERY_RESULT_BACKEND
)

# ==================== ìš°ì„ ìˆœìœ„ í ì •ì˜ ====================
# high: ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìƒì„±, ê¸´ê¸‰ ì‘ì—…
# default: ì¼ë°˜ ì˜ìƒ ë Œë”ë§
# low: ë°°ì¹˜ ì‘ì—…, í†µê³„ ìƒì„±

default_exchange = Exchange('default', type='direct')

celery_app.conf.task_queues = (
    Queue('high_priority', exchange=default_exchange, routing_key='high', priority=10),
    Queue('default', exchange=default_exchange, routing_key='default', priority=5),
    Queue('low_priority', exchange=default_exchange, routing_key='low', priority=1),
)

celery_app.conf.task_default_queue = 'default'
celery_app.conf.task_default_exchange = 'default'
celery_app.conf.task_default_routing_key = 'default'

# ==================== Celery ìµœì í™” ì„¤ì • ====================
celery_app.conf.update(
    # ì§ë ¬í™”
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',

    # íƒ€ì„ì¡´
    timezone='Asia/Seoul',
    enable_utc=True,

    # Task ì¶”ì 
    task_track_started=True,
    task_send_sent_event=True,

    # ì‹œê°„ ì œí•œ
    task_time_limit=30 * 60,  # 30ë¶„ í•˜ë“œ ì œí•œ
    task_soft_time_limit=25 * 60,  # 25ë¶„ ì†Œí”„íŠ¸ ì œí•œ

    # Worker ìµœì í™”
    worker_prefetch_multiplier=4,  # ë™ì‹œ ì²˜ë¦¬ 4ê°œ (ë³€ê²½: 1 â†’ 4)
    worker_max_tasks_per_child=100,  # 100ê°œ ì²˜ë¦¬ í›„ ì¬ì‹œì‘ (ë³€ê²½: 50 â†’ 100)
    worker_disable_rate_limits=False,

    # Retry ì „ëµ (Exponential Backoff)
    task_acks_late=True,  # Task ì™„ë£Œ í›„ ACK (ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„)
    task_reject_on_worker_lost=True,
    task_default_retry_delay=60,  # ê¸°ë³¸ ì¬ì‹œë„ ëŒ€ê¸°: 60ì´ˆ
    task_max_retries=3,  # ìµœëŒ€ ì¬ì‹œë„: 3íšŒ

    # Result Backend ìµœì í™”
    result_expires=3600,  # ê²°ê³¼ 1ì‹œê°„ í›„ ìë™ ì‚­ì œ
    result_persistent=False,  # ê²°ê³¼ ì˜êµ¬ ì €ì¥ ë¹„í™œì„±í™” (ë©”ëª¨ë¦¬ ì ˆì•½)

    # Broker ìµœì í™”
    broker_connection_retry_on_startup=True,
    broker_connection_max_retries=10,

    # ìš°ì„ ìˆœìœ„ í™œì„±í™”
    task_inherit_parent_priority=True,

    # Beat (ìŠ¤ì¼€ì¤„ëŸ¬) ì„¤ì •
    beat_schedule={
        'cleanup-old-results': {
            'task': 'cleanup_old_task_results',
            'schedule': 3600.0,  # 1ì‹œê°„ë§ˆë‹¤
        },
    },
)

# Task ìë™ ë°œê²¬
celery_app.autodiscover_tasks(['app.tasks'])

logger = logging.getLogger(__name__)


# ==================== Celery ì‹œê·¸ë„ (ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§) ====================

# Task ì‹¤í–‰ ì‹œê°„ ì¶”ì ìš© ë”•ì…”ë„ˆë¦¬
task_start_times = {}


@task_prerun.connect
def task_prerun_handler(sender=None, task_id=None, task=None, args=None, kwargs=None, **extra):
    """ì‘ì—… ì‹œì‘ ì „ ë¡œê¹… ë° ì‹œê°„ ê¸°ë¡"""
    task_start_times[task_id] = time.time()
    logger.info(
        f"â±ï¸  Task started: {task.name} (ID: {task_id[:8]}...)"
        f" | Args: {args[:2] if args else '[]'}..."
    )


@task_postrun.connect
def task_postrun_handler(sender=None, task_id=None, task=None, retval=None, **kwargs):
    """ì‘ì—… ì™„ë£Œ í›„ ë¡œê¹… ë° ì‹¤í–‰ ì‹œê°„ ì¸¡ì •"""
    if task_id in task_start_times:
        elapsed = time.time() - task_start_times[task_id]
        logger.info(
            f"âœ… Task completed: {task.name} (ID: {task_id[:8]}...)"
            f" | Duration: {elapsed:.2f}s"
        )
        del task_start_times[task_id]
    else:
        logger.info(f"âœ… Task completed: {task.name} (ID: {task_id[:8]}...)")


@task_failure.connect
def task_failure_handler(sender=None, task_id=None, exception=None, traceback=None, **kwargs):
    """ì‘ì—… ì‹¤íŒ¨ ì‹œ ë¡œê¹…"""
    if task_id in task_start_times:
        elapsed = time.time() - task_start_times[task_id]
        logger.error(
            f"âŒ Task failed: {sender.name} (ID: {task_id[:8]}...)"
            f" | Duration: {elapsed:.2f}s | Error: {exception}"
        )
        del task_start_times[task_id]
    else:
        logger.error(
            f"âŒ Task failed: {sender.name} (ID: {task_id[:8]}...)"
            f" | Error: {exception}"
        )


@task_retry.connect
def task_retry_handler(sender=None, task_id=None, reason=None, **kwargs):
    """ì‘ì—… ì¬ì‹œë„ ì‹œ ë¡œê¹…"""
    logger.warning(
        f"ğŸ”„ Task retry: {sender.name} (ID: {task_id[:8]}...)"
        f" | Reason: {reason}"
    )


# ==================== ìœ í‹¸ë¦¬í‹° ì‘ì—… ====================

@celery_app.task(name="health_check", queue='high_priority')
def health_check():
    """Celery ì›Œì»¤ í—¬ìŠ¤ì²´í¬"""
    return {"status": "healthy", "message": "Celery worker is running"}


@celery_app.task(name="cleanup_old_task_results", queue='low_priority')
def cleanup_old_task_results():
    """ì˜¤ë˜ëœ Task ê²°ê³¼ ì •ë¦¬ (1ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰)"""
    from celery.result import AsyncResult

    # Redisì—ì„œ ë§Œë£Œëœ ê²°ê³¼ ì‚­ì œ (ìë™ìœ¼ë¡œ ì²˜ë¦¬ë˜ì§€ë§Œ ëª…ì‹œì  ì •ë¦¬)
    logger.info("ğŸ§¹ Cleaning up old task results...")

    # ì—¬ê¸°ì— ì¶”ê°€ ì •ë¦¬ ë¡œì§ êµ¬í˜„ ê°€ëŠ¥
    # ì˜ˆ: íŒŒì¼ ì‹œìŠ¤í…œì˜ ì„ì‹œ íŒŒì¼ ì‚­ì œ ë“±

    return {"status": "success", "message": "Old task results cleaned up"}


# ==================== Task ìš°ì„ ìˆœìœ„ í—¬í¼ ====================

def get_task_priority(task_name: str) -> str:
    """Task ì´ë¦„ì— ë”°ë¥¸ ìš°ì„ ìˆœìœ„ ë°˜í™˜"""
    high_priority_tasks = [
        'generate_verified_audio_task',
        'health_check',
    ]

    low_priority_tasks = [
        'batch_generate_verified_audio_task',
        'cleanup_old_task_results',
    ]

    if any(name in task_name for name in high_priority_tasks):
        return 'high_priority'
    elif any(name in task_name for name in low_priority_tasks):
        return 'low_priority'
    else:
        return 'default'
