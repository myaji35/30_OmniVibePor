#!/bin/bash

# SQLite3 ë°ì´í„°ë² ì´ìŠ¤ ìë™ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸
# Cron ì„¤ì • ì˜ˆì‹œ: 0 2 * * * /path/to/backup_db.sh

set -e  # ì—ëŸ¬ ë°œìƒ ì‹œ ì¢…ë£Œ

# ì„¤ì •
DB_PATH="/Volumes/Extreme SSD/02_GitHub.nosync/0030_OmniVibePro/backend/omni_db.sqlite"
BACKUP_DIR="/Volumes/Extreme SSD/02_GitHub.nosync/0030_OmniVibePro/backend/backups"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_NAME="omni_db_backup_${TIMESTAMP}.sqlite"
KEEP_DAYS=7  # 7ì¼ ì´ìƒ ëœ ë°±ì—… ì‚­ì œ

# ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p "$BACKUP_DIR"

echo "ğŸš€ Starting database backup..."
echo "  Source: $DB_PATH"
echo "  Destination: $BACKUP_DIR/$BACKUP_NAME"

# 1. SQLite ë°±ì—… (VACUUM INTO ì‚¬ìš© - ê°€ì¥ ì•ˆì „)
if command -v sqlite3 &> /dev/null; then
    sqlite3 "$DB_PATH" "VACUUM INTO '$BACKUP_DIR/$BACKUP_NAME'"
    echo "âœ“ Backup created using VACUUM INTO"
else
    # sqlite3 ëª…ë ¹ì–´ê°€ ì—†ìœ¼ë©´ íŒŒì¼ ë³µì‚¬
    cp "$DB_PATH" "$BACKUP_DIR/$BACKUP_NAME"

    # WAL íŒŒì¼ë„ ë°±ì—… (ì¡´ì¬í•˜ëŠ” ê²½ìš°)
    if [ -f "${DB_PATH}-wal" ]; then
        cp "${DB_PATH}-wal" "${BACKUP_DIR}/${BACKUP_NAME}-wal"
    fi

    # SHM íŒŒì¼ë„ ë°±ì—… (ì¡´ì¬í•˜ëŠ” ê²½ìš°)
    if [ -f "${DB_PATH}-shm" ]; then
        cp "${DB_PATH}-shm" "${BACKUP_DIR}/${BACKUP_NAME}-shm"
    fi

    echo "âœ“ Backup created using file copy"
fi

# 2. ë°±ì—… íŒŒì¼ ì••ì¶• (gzip)
gzip "$BACKUP_DIR/$BACKUP_NAME"
echo "âœ“ Backup compressed: ${BACKUP_NAME}.gz"

# 3. ë°±ì—… íŒŒì¼ í¬ê¸° í™•ì¸
BACKUP_SIZE=$(du -h "$BACKUP_DIR/${BACKUP_NAME}.gz" | cut -f1)
echo "  Backup size: $BACKUP_SIZE"

# 4. ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ (7ì¼ ì´ìƒ)
echo "ğŸ§¹ Cleaning up old backups (older than $KEEP_DAYS days)..."
find "$BACKUP_DIR" -name "omni_db_backup_*.sqlite.gz" -type f -mtime +$KEEP_DAYS -delete
echo "âœ“ Old backups cleaned up"

# 5. í˜„ì¬ ë°±ì—… ê°œìˆ˜ í™•ì¸
BACKUP_COUNT=$(find "$BACKUP_DIR" -name "omni_db_backup_*.sqlite.gz" -type f | wc -l | tr -d ' ')
echo "  Total backups: $BACKUP_COUNT"

echo "âœ… Backup completed successfully!"

# 6. (ì„ íƒì‚¬í•­) ì›ê²© ìŠ¤í† ë¦¬ì§€ì— ì—…ë¡œë“œ (S3, Google Cloud Storage ë“±)
# aws s3 cp "$BACKUP_DIR/${BACKUP_NAME}.gz" s3://my-bucket/backups/
# rclone copy "$BACKUP_DIR/${BACKUP_NAME}.gz" gdrive:backups/

exit 0
